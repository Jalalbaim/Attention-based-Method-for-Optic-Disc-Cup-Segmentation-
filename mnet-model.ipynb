{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10057029,"sourceType":"datasetVersion","datasetId":6197175},{"sourceId":10072311,"sourceType":"datasetVersion","datasetId":6208316}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training MNet","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras import backend as K\nimport scipy\nfrom skimage.measure import label, regionprops\nimport os\nfrom keras.preprocessing import image\nimport tensorflow as tf\nfrom keras.optimizers import SGD\nfrom keras.layers import (\n    Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization,\n    Activation, Conv2DTranspose, Multiply, Add, AveragePooling2D, Average\n)\nfrom keras.models import Model\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.424317Z","iopub.execute_input":"2024-12-04T04:11:50.424973Z","iopub.status.idle":"2024-12-04T04:11:50.430587Z","shell.execute_reply.started":"2024-12-04T04:11:50.424937Z","shell.execute_reply":"2024-12-04T04:11:50.429496Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"# Define helper functions\ndef mk_dir(dir_path):\n    if not os.path.exists(dir_path):\n        os.makedirs(dir_path)\n    return dir_path\n\ndef return_list(data_path, data_type):\n    file_list = [file for file in os.listdir(data_path) if file.lower().endswith(data_type)]\n    print(str(len(file_list)))\n    return file_list\n\ndef train_loader(data_list, data_path, mask_path, input_size):\n    for lineIdx in range(len(data_list)):\n        temp_txt = data_list[lineIdx]\n\n        train_img = np.asarray(image.load_img(\n            os.path.join(data_path, temp_txt),\n            target_size=(input_size, input_size, 3))\n        ).astype('float32')\n\n        img_mask = np.asarray(image.load_img(\n            os.path.join(mask_path, temp_txt),\n            target_size=(input_size, input_size, 3))) / 255.0\n\n        img_mask = img_mask.astype('float32')\n\n        yield (train_img, (img_mask, img_mask, img_mask, img_mask, img_mask))\n\n\ndef tf_data_loader(data_list, data_path, mask_path, input_size):\n    dataset = tf.data.Dataset.from_generator(\n        lambda: train_loader(data_list, data_path, mask_path, input_size),\n        output_signature=(\n            tf.TensorSpec(shape=(input_size, input_size, 3), dtype=tf.float32),\n            tuple([tf.TensorSpec(shape=(input_size, input_size, 3), dtype=tf.float32)] * 5)\n        )\n    )\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.431971Z","iopub.execute_input":"2024-12-04T04:11:50.432245Z","iopub.status.idle":"2024-12-04T04:11:50.450687Z","shell.execute_reply.started":"2024-12-04T04:11:50.432220Z","shell.execute_reply":"2024-12-04T04:11:50.449857Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Training Settings\nresult_path = mk_dir('/kaggle/working/output_deep_model/')\npre_model_file = '/kaggle/input/deep-model/deep_model/Model_MNet_REFUGE.h5'\nsave_model_file = result_path + 'Model_MNet_REFUGE_v2.h5'\n\nroot_path = '/kaggle/input/training-data-polar/training_crop/'\ntrain_data_path = root_path + 'data/'\ntrain_mask_path = root_path + 'label/'\n\nval_data_path = root_path + 'val_data/data/'\nval_mask_path = root_path + 'val_data/label/'\n\ntrain_list = return_list(train_data_path, '.png')\nval_list = return_list(val_data_path, '.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.478231Z","iopub.execute_input":"2024-12-04T04:11:50.478473Z","iopub.status.idle":"2024-12-04T04:11:50.495852Z","shell.execute_reply.started":"2024-12-04T04:11:50.478450Z","shell.execute_reply":"2024-12-04T04:11:50.495172Z"}},"outputs":[{"name":"stdout","text":"1400\n300\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Model MNet","metadata":{}},{"cell_type":"code","source":"from keras.layers import (\n    Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization,\n    Activation, Conv2DTranspose, Multiply, Add, AveragePooling2D, Average\n)\nfrom keras.models import Model\n\ndef attention_gate(x, g, inter_channels):\n    # x: Input feature map from the encoder (skip connection)\n    # g: Gating signal from the decoder\n    # inter_channels: Number of filters for intermediate computations\n\n    theta_x = Conv2D(inter_channels, (2, 2), strides=(2, 2), padding='same')(x)\n    phi_g = Conv2D(inter_channels, (1, 1), padding='same')(g)\n    add = Add()([theta_x, phi_g])\n    relu = Activation('relu')(add)\n    psi = Conv2D(1, (1, 1), padding='same')(relu)\n    sigmoid = Activation('sigmoid')(psi)\n    upsampled = UpSampling2D(size=(2, 2), interpolation='bilinear')(sigmoid)\n    attn_coefficients = Multiply()([x, upsampled])\n    return attn_coefficients\n\ndef DeepModel(size_set=800):\n\n    img_input = Input(shape=(size_set, size_set, 3))\n\n    # Scaled inputs\n    scale_img_2 = AveragePooling2D(pool_size=(2, 2))(img_input)\n    scale_img_3 = AveragePooling2D(pool_size=(2, 2))(scale_img_2)\n    scale_img_4 = AveragePooling2D(pool_size=(2, 2))(scale_img_3)\n\n    # Block 1\n    conv1 = Conv2D(32, (3, 3), padding='same', name='block1_conv1')(img_input)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv1 = Conv2D(32, (3, 3), padding='same', name='block1_conv2')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n    # Block 2\n    input2 = Conv2D(64, (3, 3), padding='same', name='block2_input1')(scale_img_2)\n    input2 = BatchNormalization()(input2)\n    input2 = Activation('relu')(input2)\n    input2 = concatenate([input2, pool1], axis=3)\n    conv2 = Conv2D(64, (3, 3), padding='same', name='block2_conv1')(input2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    conv2 = Conv2D(64, (3, 3), padding='same', name='block2_conv2')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    # Block 3\n    input3 = Conv2D(128, (3, 3), padding='same', name='block3_input1')(scale_img_3)\n    input3 = BatchNormalization()(input3)\n    input3 = Activation('relu')(input3)\n    input3 = concatenate([input3, pool2], axis=3)\n    conv3 = Conv2D(128, (3, 3), padding='same', name='block3_conv1')(input3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv3 = Conv2D(128, (3, 3), padding='same', name='block3_conv2')(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n    # Block 4\n    input4 = Conv2D(256, (3, 3), padding='same', name='block4_input1')(scale_img_4)\n    input4 = BatchNormalization()(input4)\n    input4 = Activation('relu')(input4)\n    input4 = concatenate([input4, pool3], axis=3)\n    conv4 = Conv2D(256, (3, 3), padding='same', name='block4_conv1')(input4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    conv4 = Conv2D(256, (3, 3), padding='same', name='block4_conv2')(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = Activation('relu')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n    # Bridge\n    conv5 = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(pool4)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n    conv5 = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(conv5)\n    conv5 = BatchNormalization()(conv5)\n    conv5 = Activation('relu')(conv5)\n\n    # Decoder with Attention Gates\n    # Up Block 6\n    attn4 = attention_gate(conv4, conv5, inter_channels=256)\n    up6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', name='block6_dconv')(conv5)\n    up6 = concatenate([up6, attn4], axis=3)\n    conv6 = Conv2D(256, (3, 3), padding='same', name='block6_conv1')(up6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n    conv6 = Conv2D(256, (3, 3), padding='same', name='block6_conv2')(conv6)\n    conv6 = BatchNormalization()(conv6)\n    conv6 = Activation('relu')(conv6)\n\n    # Up Block 7\n    attn3 = attention_gate(conv3, conv6, inter_channels=128)\n    up7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', name='block7_dconv')(conv6)\n    up7 = concatenate([up7, attn3], axis=3)\n    conv7 = Conv2D(128, (3, 3), padding='same', name='block7_conv1')(up7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n    conv7 = Conv2D(128, (3, 3), padding='same', name='block7_conv2')(conv7)\n    conv7 = BatchNormalization()(conv7)\n    conv7 = Activation('relu')(conv7)\n\n    # Up Block 8\n    attn2 = attention_gate(conv2, conv7, inter_channels=64)\n    up8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', name='block8_dconv')(conv7)\n    up8 = concatenate([up8, attn2], axis=3)\n    conv8 = Conv2D(64, (3, 3), padding='same', name='block8_conv1')(up8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n    conv8 = Conv2D(64, (3, 3), padding='same', name='block8_conv2')(conv8)\n    conv8 = BatchNormalization()(conv8)\n    conv8 = Activation('relu')(conv8)\n\n    # Up Block 9\n    attn1 = attention_gate(conv1, conv8, inter_channels=32)\n    up9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', name='block9_dconv')(conv8)\n    up9 = concatenate([up9, attn1], axis=3)\n    conv9 = Conv2D(32, (3, 3), padding='same', name='block9_conv1')(up9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n    conv9 = Conv2D(32, (3, 3), padding='same', name='block9_conv2')(conv9)\n    conv9 = BatchNormalization()(conv9)\n    conv9 = Activation('relu')(conv9)\n\n    # Side Outputs with 1 channel each\n    side6 = UpSampling2D(size=(8, 8))(conv6)\n    side7 = UpSampling2D(size=(4, 4))(conv7)\n    side8 = UpSampling2D(size=(2, 2))(conv8)\n    out6 = Conv2D(3, (1, 1), activation='softmax', name='side_63')(side6)\n    out7 = Conv2D(3, (1, 1), activation='softmax', name='side_73')(side7)\n    out8 = Conv2D(3, (1, 1), activation='softmax', name='side_83')(side8)\n    out9 = Conv2D(3, (1, 1), activation='softmax', name='side_93')(conv9)\n    \n    # Final Output with name 'final_output'\n    out10 = Average(name='final_output')([out6, out7, out8, out9])\n\n    model = Model(inputs=[img_input], outputs=[out6, out7, out8, out9, out10])\n\n    return model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.497546Z","iopub.execute_input":"2024-12-04T04:11:50.497985Z","iopub.status.idle":"2024-12-04T04:11:50.523306Z","shell.execute_reply.started":"2024-12-04T04:11:50.497947Z","shell.execute_reply":"2024-12-04T04:11:50.522392Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Training ","metadata":{}},{"cell_type":"code","source":"# # Set the root and data paths\n# root_path = '/kaggle/input/training-data-polar/training_crop/'\n# train_data_path = os.path.join(root_path, 'data/')\n# train_mask_path = os.path.join(root_path, 'label/')\n\n# val_data_path = os.path.join(root_path, 'val_data/data/')\n# val_mask_path = os.path.join(root_path, 'val_data/label/')\n\n# # Define image dimensions\n# IMAGE_SIZE = 800  # As per your model's input size\n\n# # Function to load and preprocess images\n# def load_image(path, target_size):\n#     img = load_img(path, target_size=(target_size, target_size))\n#     img = img_to_array(img)\n#     img = img / 255.0  # Normalize to [0, 1]\n#     return img\n\n# # Function to load and preprocess masks\n# def load_mask(path, target_size):\n#     mask = load_img(path, target_size=(target_size, target_size), color_mode='grayscale')\n#     mask = img_to_array(mask)\n#     mask = mask / 255.0  # Normalize to [0, 1]\n#     mask = np.round(mask)  # Ensure binary masks\n#     return mask\n\n# # Custom data generator\n# class DataGenerator(Sequence):\n#     def __init__(self, image_filenames, mask_filenames, image_dir, mask_dir, batch_size, target_size, shuffle=True):\n#         self.image_filenames = image_filenames\n#         self.mask_filenames = mask_filenames\n#         self.image_dir = image_dir\n#         self.mask_dir = mask_dir\n#         self.batch_size = batch_size\n#         self.target_size = target_size\n#         self.shuffle = shuffle\n#         self.on_epoch_end()\n    \n#     def __len__(self):\n#         return int(np.ceil(len(self.image_filenames) / self.batch_size))\n    \n#     def __getitem__(self, index):\n#         # Generate indexes of the batch\n#         batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        \n#         # Find list of IDs\n#         batch_image_filenames = [self.image_filenames[k] for k in batch_indexes]\n#         batch_mask_filenames = [self.mask_filenames[k] for k in batch_indexes]\n        \n#         # Generate data\n#         X, Y = self.__data_generation(batch_image_filenames, batch_mask_filenames)\n        \n#         return X, Y\n    \n#     def on_epoch_end(self):\n#         self.indexes = np.arange(len(self.image_filenames))\n#         if self.shuffle:\n#             np.random.shuffle(self.indexes)\n    \n#     def __data_generation(self, batch_image_filenames, batch_mask_filenames):\n#         X = np.empty((len(batch_image_filenames), self.target_size, self.target_size, 3), dtype=np.float32)\n#         Y = np.empty((len(batch_mask_filenames), self.target_size, self.target_size, 1), dtype=np.float32)\n        \n#         for i, (img_name, mask_name) in enumerate(zip(batch_image_filenames, batch_mask_filenames)):\n#             img_path = os.path.join(self.image_dir, img_name)\n#             mask_path = os.path.join(self.mask_dir, mask_name)\n            \n#             # Load and preprocess images and masks\n#             img = load_image(img_path, self.target_size)\n#             mask = load_mask(mask_path, self.target_size)\n            \n#             X[i] = img\n#             Y[i] = mask\n        \n#         # Prepare outputs as a dictionary mapping output names to targets\n#         Y_multi = {\n#             'side_63': Y,\n#             'side_73': Y,\n#             'side_83': Y,\n#             'side_93': Y,\n#             'final_output': Y\n#         }\n#         return X, Y_multi\n\n\n# # Get the list of image and mask filenames for training\n# train_image_files = sorted(os.listdir(train_data_path))\n# train_mask_files = sorted(os.listdir(train_mask_path))\n\n# # Get the list of image and mask filenames for validation\n# val_image_files = sorted(os.listdir(val_data_path))\n# val_mask_files = sorted(os.listdir(val_mask_path))\n\n# # Create data generators\n# batch_size = 4  # Adjust based on your GPU memory\n\n# train_generator = DataGenerator(\n#     train_image_files, train_mask_files,\n#     train_data_path, train_mask_path,\n#     batch_size=batch_size, target_size=IMAGE_SIZE, shuffle=True\n# )\n\n# val_generator = DataGenerator(\n#     val_image_files, val_mask_files,\n#     val_data_path, val_mask_path,\n#     batch_size=batch_size, target_size=IMAGE_SIZE, shuffle=False\n# )\n\n# # Define the model\n# model = DeepModel(size_set=IMAGE_SIZE)\n\n# # Compile the model with dictionaries for losses and loss_weights\n# losses = {\n#     'side_63': 'binary_crossentropy',\n#     'side_73': 'binary_crossentropy',\n#     'side_83': 'binary_crossentropy',\n#     'side_93': 'binary_crossentropy',\n#     'final_output': 'binary_crossentropy'\n# }\n\n# loss_weights = {\n#     'side_63': 0.1,\n#     'side_73': 0.1,\n#     'side_83': 0.1,\n#     'side_93': 0.1,\n#     'final_output': 0.6\n# }\n\n# def dice_coefficient(y_true, y_pred):\n#     smooth = 1.  # Avoid division by zero\n#     y_true_f = K.flatten(y_true)\n#     y_pred_f = K.flatten(y_pred)\n#     intersection = K.sum(y_true_f * y_pred_f)\n#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# metrics = {\n#     'side_63': ['accuracy'],\n#     'side_73': ['accuracy'],\n#     'side_83': ['accuracy'],\n#     'side_93': ['accuracy'],\n#     'final_output': ['accuracy']#, dice_coefficie\n# }\n\n# model.compile(\n#     optimizer=Adam(learning_rate=1e-4),\n#     loss=losses,\n#     loss_weights=loss_weights,\n#     metrics= metrics,\n# )\n\n# # Callbacks\n# checkpoint = ModelCheckpoint(\n#     '/kaggle/working/best_model.weights.h5',\n#     monitor='val_loss',\n#     verbose=1,\n#     save_best_only=True,\n#     mode='min',\n#     save_weights_only=True\n# )\n\n# reduce_lr = ReduceLROnPlateau(\n#     monitor='val_loss',\n#     factor=0.5,\n#     patience=5,\n#     min_lr=1e-7,\n#     verbose=1\n# )\n\n# early_stopping = EarlyStopping(\n#     monitor='val_loss',\n#     patience=10,\n#     restore_best_weights=True\n# )\n\n# callbacks_list = [checkpoint, reduce_lr, early_stopping]\n\n# # Train the model\n# epochs = 50  # Adjust as needed\n# print(\"Start training\")\n# model.fit(\n#     train_generator,\n#     validation_data=val_generator,\n#     epochs=epochs,\n#     callbacks=callbacks_list\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.545249Z","iopub.execute_input":"2024-12-04T04:11:50.545587Z","iopub.status.idle":"2024-12-04T04:11:50.554230Z","shell.execute_reply.started":"2024-12-04T04:11:50.545546Z","shell.execute_reply":"2024-12-04T04:11:50.553473Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"Total_iter = 10\nnb_epoch_setting = 3\ninput_size = 400\noptimizer_setting = SGD(learning_rate=0.0001, momentum=0.9)\n\n# Build and compile the model\nmy_model = DeepModel(size_set=input_size)\n# my_model.load_weights(pre_model_file, by_name=True)\n\nmy_model.compile(optimizer=optimizer_setting, loss='categorical_crossentropy',\n                 loss_weights=[0.1, 0.1, 0.1, 0.1, 0.6])\n\nprint(my_model.input_shape)  # Should output (None, 400, 400, 3)\n\n# Data Preparation\ntrain_dataset = tf_data_loader(train_list, train_data_path, train_mask_path, input_size)\nval_dataset = tf_data_loader(val_list, val_data_path, val_mask_path, input_size)\n\ntrain_dataset = train_dataset.shuffle(buffer_size=len(train_list)).batch(8).repeat().prefetch(tf.data.AUTOTUNE)\nval_dataset = val_dataset.batch(8).repeat().prefetch(tf.data.AUTOTUNE)\n\nbatch_size = 8\nsteps_per_epoch = len(train_list) // batch_size\nvalidation_steps = len(val_list) // batch_size\n\n# Verify data shapes\nfor images, labels in train_dataset.take(1):\n    print(\"Image shape:\", images.shape)  # Expected: (batch_size, input_size, input_size, 3)\n    for idx, label in enumerate(labels):\n        print(f\"Label {idx+1} shape:\", label.shape)  # Expected: (batch_size, input_size, input_size, 3)\n\n# Training Loop\nloss_max = 10000\nfor idx_iter in range(Total_iter):\n    print(\"Training started\")\n    model_return = my_model.fit(\n        x=train_dataset,\n        validation_data=val_dataset,\n        epochs=nb_epoch_setting,\n        steps_per_epoch=steps_per_epoch,\n        validation_steps=validation_steps,\n        verbose=1\n    )\n    val_loss = model_return.history['val_loss'][0]\n    train_loss = model_return.history['loss'][0]\n    if val_loss < loss_max:\n        my_model.save(save_model_file)\n        loss_max = val_loss\n        print('[Save] training iter: ' + str(idx_iter+1) +\n              ', train_loss: ' + str(train_loss) +\n              ', val_loss: ' + str(val_loss))\n    else:\n        print('[None] training iter: ' + str(idx_iter+1) +\n              ', train_loss: ' + str(train_loss) +\n              ', val_loss: ' + str(val_loss))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T04:11:50.594462Z","iopub.execute_input":"2024-12-04T04:11:50.594678Z"}},"outputs":[{"name":"stdout","text":"(None, 400, 400, 3)\nImage shape: (8, 400, 400, 3)\nLabel 1 shape: (8, 400, 400, 3)\nLabel 2 shape: (8, 400, 400, 3)\nLabel 3 shape: (8, 400, 400, 3)\nLabel 4 shape: (8, 400, 400, 3)\nLabel 5 shape: (8, 400, 400, 3)\nTraining started\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733285619.664391      96 service.cc:145] XLA service 0x7a9d2400a3f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1733285619.664449      96 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1733285655.511448      96 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_13', 972 bytes spill stores, 904 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'input_compare_reduce_fusion', 96 bytes spill stores, 96 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion_3', 104 bytes spill stores, 104 bytes spill loads\nptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion', 64 bytes spill stores, 64 bytes spill loads\n\nI0000 00:00:1733285655.541913      96 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 428ms/step - loss: 0.8556 - val_loss: 0.7268\nEpoch 2/3\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Validation try","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to load a single image and mask\ndef load_single_image(img_path, mask_path, target_size):\n    img = load_image(img_path, target_size)\n    mask = load_mask(mask_path, target_size)\n    return img, mask\n\n# Select a sample from the validation set\nsample_index = 0\nsample_img_name = val_image_files[sample_index]\nsample_mask_name = val_mask_files[sample_index]\n\nsample_img_path = os.path.join(val_data_path, sample_img_name)\nsample_mask_path = os.path.join(val_mask_path, sample_mask_name)\n\n# Load the image and mask\nimg, mask = load_single_image(sample_img_path, sample_mask_path, IMAGE_SIZE)\nimg_input = np.expand_dims(img, axis=0)  # Add batch dimension\n\n# Predict\npredictions = model.predict(img_input)\nfinal_output = predictions[-1][0]  # Extract the first sample from the batch\n\n# Threshold the output to get binary mask\nbinary_mask = (final_output > 0.5).astype(np.uint8)\n\n# Visualization\nplt.figure(figsize=(15, 5))\n\nplt.subplot(1, 3, 1)\nplt.imshow(img)\nplt.title('Input Image')\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.imshow(mask.squeeze())\nplt.title('Ground Truth Mask')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.imshow(binary_mask.squeeze())\nplt.title('Predicted Mask')\nplt.axis('off')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}